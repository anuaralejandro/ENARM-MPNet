%% References for ENARM-MPNet Paper
%% Format: BibTeX for Elsevier Vancouver style

%% ===== LANGUAGE MODELS & EMBEDDINGS =====

@article{lee2020biobert,
  title={{BioBERT}: a pre-trained biomedical language representation model for biomedical text mining},
  author={Lee, Jinhyuk and Yoon, Wonjin and Kim, Sungdong and Kim, Donghyeon and Kim, Sunkyu and So, Chan Ho and Kang, Jaewoo},
  journal={Bioinformatics},
  volume={36},
  number={4},
  pages={1234--1240},
  year={2020},
  publisher={Oxford University Press}
}

@article{alsentzer2019publicly,
  title={Publicly Available Clinical {BERT} Embeddings},
  author={Alsentzer, Emily and Murphy, John R and Boag, Willie and Weng, Wei-Hung and Jin, Di and Naumann, Tristan and McDermott, Matthew BA},
  journal={Proceedings of the 2nd Clinical Natural Language Processing Workshop},
  pages={72--78},
  year={2019}
}

@article{gu2021domain,
  title={Domain-Specific Pretraining for Vertical Search: Case Study on Biomedical Literature},
  author={Gu, Yu and Tinn, Robert and Cheng, Hao and Lucas, Michael and Usuyama, Naoto and Liu, Xiaodong and Naumann, Tristan and Gao, Jianfeng and Poon, Hoifung},
  journal={arXiv preprint arXiv:2007.15779},
  year={2021}
}

@article{rasmy2021medbert,
  title={{Med-BERT}: pretrained contextualized embeddings on large-scale structured electronic health records for disease prediction},
  author={Rasmy, Laila and Xiang, Yang and Xie, Ziqian and Tao, Cui and Zhi, Degui},
  journal={NPJ Digital Medicine},
  volume={4},
  number={1},
  pages={1--13},
  year={2021},
  publisher={Nature Publishing Group}
}

@inproceedings{reimers2019sentence,
  title={Sentence-{BERT}: Sentence Embeddings using Siamese {BERT}-Networks},
  author={Reimers, Nils and Gurevych, Iryna},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={3982--3992},
  year={2019}
}

@inproceedings{song2020mpnet,
  title={{MPNet}: Masked and Permuted Pre-training for Language Understanding},
  author={Song, Kaitao and Tan, Xu and Qin, Tao and Lu, Jianfeng and Liu, Tie-Yan},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={33},
  pages={16857--16867},
  year={2020}
}

@article{devlin2019bert,
  title={{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={Proceedings of NAACL-HLT},
  pages={4171--4186},
  year={2019}
}

%% ===== CONTRASTIVE LEARNING =====

@inproceedings{henderson2017efficient,
  title={Efficient Natural Language Response Suggestion for Smart Reply},
  author={Henderson, Matthew and Al-Rfou, Rami and Strope, Brian and Sung, Yun-Hsuan and Luk{\'a}cs, L{\'a}szl{\'o} and Guo, Ruiqi and Kumar, Sanjiv and Miklos, Balint and Kurzweil, Ray},
  booktitle={arXiv preprint arXiv:1705.00652},
  year={2017}
}

@article{chen2020simple,
  title={A Simple Framework for Contrastive Learning of Visual Representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  journal={International Conference on Machine Learning (ICML)},
  pages={1597--1607},
  year={2020}
}

@inproceedings{gao2021simcse,
  title={{SimCSE}: Simple Contrastive Learning of Sentence Embeddings},
  author={Gao, Tianyu and Yao, Xingcheng and Chen, Danqi},
  booktitle={Proceedings of EMNLP},
  pages={6894--6910},
  year={2021}
}

%% ===== RAG & RETRIEVAL =====

@inproceedings{lewis2020retrieval,
  title={Retrieval-Augmented Generation for Knowledge-Intensive {NLP} Tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and Riedel, Sebastian and Kiela, Douwe},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={33},
  pages={9459--9474},
  year={2020}
}

@article{karpukhin2020dense,
  title={Dense Passage Retrieval for Open-Domain Question Answering},
  author={Karpukhin, Vladimir and O{\u{g}}uz, Barlas and Min, Sewon and Lewis, Patrick and Wu, Ledell and Edunov, Sergey and Chen, Danqi and Yih, Wen-tau},
  journal={Proceedings of EMNLP},
  pages={6769--6781},
  year={2020}
}

@article{gao2023retrieval,
  title={Retrieval-Augmented Generation for Large Language Models: A Survey},
  author={Gao, Yunfan and Xiong, Yun and Gao, Xinyu and Jia, Kangxiang and Pan, Jinliu and Bi, Yuxi and Dai, Yi and Sun, Jiawei and Wang, Haofen},
  journal={arXiv preprint arXiv:2312.10997},
  year={2023}
}

%% ===== AI IN MEDICAL EDUCATION =====

@article{kung2023performance,
  title={Performance of {ChatGPT} on {USMLE}: Potential for AI-assisted medical education using large language models},
  author={Kung, Tiffany H and Cheatham, Morgan and Medenilla, Arielle and Sillos, Czarina and De Leon, Lorie and Elepa{\~n}o, Camille and Madriaga, Maria and Aggabao, Rimel and Diaz-Candido, Giezel and Maningo, James and Tseng, Victor},
  journal={PLOS Digital Health},
  volume={2},
  number={2},
  pages={e0000198},
  year={2023},
  publisher={Public Library of Science}
}

@article{lee2023benefits,
  title={The Benefits, Risks, and Limitations of {ChatGPT} in Medical Education and Clinical Practice},
  author={Lee, Peter and Bubeck, S{\'e}bastien and Petro, Joseph},
  journal={JAMA},
  volume={330},
  number={2},
  year={2023}
}

@article{thirunavukarasu2023large,
  title={Large language models in medicine},
  author={Thirunavukarasu, Arun James and Ting, Daniel Shu Wei and Elangovan, Kabilan and Gutierrez, Laura and Tan, Ting Fang and Ting, Daniel Shu Wei},
  journal={Nature Medicine},
  volume={29},
  number={8},
  pages={1930--1940},
  year={2023},
  publisher={Nature Publishing Group}
}

@article{dave2023chatgpt,
  title={{ChatGPT} in medicine: an overview of its applications, advantages, limitations, future prospects, and ethical considerations},
  author={Dave, Tanmay and Athaluri, Sash Anil and Singh, Sukhbir},
  journal={Frontiers in Artificial Intelligence},
  volume={6},
  pages={1169595},
  year={2023}
}

%% ===== MEXICAN HEALTHCARE & ENARM =====

@misc{secretaria2024enarm,
  title={Examen Nacional de Aspirantes a Residencias M{\'e}dicas: Convocatoria 2024},
  author={{Secretar{\'i}a de Salud}},
  year={2024},
  howpublished={https://www.cifrhs.salud.gob.mx/enarm/}
}

@article{mexicohealthequity2023,
  title={Socioeconomic Inequalities in Medical Specialty Training Access in {Mexico}},
  author={{Instituto Nacional de Salud P{\'u}blica}},
  journal={Salud P{\'u}blica de M{\'e}xico},
  volume={65},
  number={3},
  pages={245--252},
  year={2023}
}

@article{cenetec2020gpc,
  title={Cat{\'a}logo Maestro de Gu{\'i}as de Pr{\'a}ctica Cl{\'i}nica},
  author={{Centro Nacional de Excelencia Tecnol{\'o}gica en Salud}},
  journal={CENETEC-Salud},
  year={2020}
}

@misc{cifrhs2024,
  title={Comisi{\'o}n Interinstitucional para la Formaci{\'o}n de Recursos Humanos para la Salud: Funciones y Atribuciones},
  author={{CIFRHS}},
  year={2024},
  howpublished={https://www.cifrhs.salud.gob.mx/}
}

@misc{conacem2023,
  title={Especialidades M{\'e}dicas Reconocidas en M{\'e}xico},
  author={{Consejo Nacional de Certificaci{\'o}n de Especialidades M{\'e}dicas}},
  year={2023},
  howpublished={https://www.conacem.org.mx/}
}

@article{ji2023survey,
  title={Survey of Hallucination in Natural Language Generation},
  author={Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Ye Jin and Madotto, Andrea and Fung, Pascale},
  journal={ACM Computing Surveys},
  volume={55},
  number={12},
  pages={1--38},
  year={2023},
  publisher={ACM}
}

@article{neves2023multilingual,
  title={Multilingual Biomedical Named Entity Recognition: A Survey of Methods, Resources, and Challenges},
  author={Neves, Mariana and Leser, Ulf},
  journal={Briefings in Bioinformatics},
  volume={24},
  number={1},
  pages={bbac498},
  year={2023},
  publisher={Oxford University Press}
}

%% ===== TRANSFORMERS & ATTENTION =====

@inproceedings{vaswani2017attention,
  title={Attention Is All You Need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={30},
  pages={5998--6008},
  year={2017}
}

%% ===== ETHICS IN AI =====

@article{char2018implementing,
  title={Implementing Machine Learning in Health Care --- Addressing Ethical Challenges},
  author={Char, Danton S and Shah, Nigam H and Magnus, David},
  journal={New England Journal of Medicine},
  volume={378},
  number={11},
  pages={981--983},
  year={2018}
}

@article{topol2019high,
  title={High-performance medicine: the convergence of human and artificial intelligence},
  author={Topol, Eric J},
  journal={Nature Medicine},
  volume={25},
  number={1},
  pages={44--56},
  year={2019}
}

@article{beam2018big,
  title={Big Data and Machine Learning in Health Care},
  author={Beam, Andrew L and Kohane, Isaac S},
  journal={JAMA},
  volume={319},
  number={13},
  pages={1317--1318},
  year={2018}
}
